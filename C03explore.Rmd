# Data exploration {#explore3}

Before attempting to analyse data, a vital first step is to perform a data exploration. A data exploration will save time by identifying any potential problems in the data and will help in deciding what type of analysis to conduct. 

## Seven-step data exploration protocol {#7step3}

We adopt a modified version of the protocol proposed by Zuur _et al_. (2010) for conducting data exploration. This protocol comprises 7 steps and is intended to identify:

**_1.	Outliers in response and independent variables_**  
**_2.	Normality and homogeneity of the response variable_**  
**_3.	Balance of categorical variables_**  
**_4.	An excess of zeros in the response variable_**  
**_5.	Multicollinearity among independent variables_**  
**_6.	Relationships among response and independent variables_**  
**_7.	Independence of the response variable_**  

It is good practice to conduct a data exploration, irrespective of the type of data you have or the analysis you plan to conduct. Here we will conduct a data exploration on the Wytham Wood blue tit data introduced in Chapter 1 from the study by O'Neill _et al_. (2018).

First, we load required libraries (see Section \@ref(functions)) and import the data (see Section \@ref(import)).

*__Load libraries__*

```{r ch3_libraries, echo=TRUE, warning=FALSE, message=FALSE}
library(arm)
library(car)
library(GGally)
library(ggplot2)
library(gridExtra)
library(lattice)
library(lawstat)
library(magrittr)
library(outliers)
library(rlang)
library(tidyverse)
```

*__Import data__*

Data for blue tit nests are saved in the comma-separated file _cyan.csv_ and can be imported into a dataframe in R using the command:  

```{r ch3-import-cyan, echo=TRUE, warning=FALSE, message=FALSE}
cyan <- read.csv(file = "cyan.csv",  
               header = TRUE,  
                  dec = ".",  
     stringsAsFactors = TRUE)
```

Start by inspecting the dataframe using the structure function `str`:

```{r ch3-str-cyan, echo=TRUE, warning=FALSE, message=FALSE}
str(cyan, width = 50, strict.width = "cut")
```

Note that the arguments `width = 50, strict.width = "cut"` simply limits the amount of information displayed

The dataframe comprises 438 observations of 7 variables. Each row in the dataframe represents a record for a blue tit nest. The variable `id` is a unique identifier for an artificial nest box in which a nest was found. Note that there are fewer levels of `id` than observations, which indicates there are multiple records (in different years) for different nests in the same nest box. This is a potential problem and we will revisit this point later. The variable `zone` represents discrete woodland compartments within Wytham Woods; there are nine levels of this categorical variable. These zones represent a discrete stand of trees in the woodland, where the composition of vegetation varies due to past management. The variable `year` is the year of data collection (varying from 2001-2003). The categorical variable `multi` indicates whether the female that built the nest bred more than once in that year (two levels; no or yes). `Height` is a continuous variable and is the vertical height (in m) at which the nest box containing the nest is attached to a tree. `Day` represents the number of days after the 1st April in a given year that the first egg was laid in the nest. Finally, `depth` is the depth of the nest, recorded as a proportion of the nest box that was filled with nesting material. Nest depth, which represents a measure of nest size, may indicate blue tit body condition or access to resources and will be our main variable of interest; i.e. our ‘response variable’.

Missing data, which are designated `NA` in the tab-delimited file, can be problematic in data analysis. Therefore, it is necessary to check if there are any missing values in the dataframe `cyan`.

```{r ch3-NAs, message = FALSE, echo=TRUE, warning=FALSE}
colSums(is.na(cyan))
```

No missing data are associated with any of the variables in the dataframe.
    
### Outliers in response and independent variables {#outliers3}

An outlier is an observation that has a relatively large or small value compared to the majority of observations. Many statistical techniques are sensitive to the presence of outliers in data. Outliers are best identified visually. For the categorical variable `zone`, we use a boxplot to visualise how `depth` varies among woodland zones.

To keep our figures tidy using a preferred figure format, we can define a set of plotting criteria as an object called `My_theme`.

```{r ch3-My-theme, warning=FALSE, echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
My_theme <- theme(panel.background = element_blank(),  
          panel.border = element_rect(fill = NA, size = 1),  
          strip.background = element_rect(fill = "white",  
          color="white"), text=element_text(size = 12),  
          panel.grid.major = element_line(colour = "white"),  
          panel.grid.minor = element_line(colour = "white"))  
```

Then plot:

(ref:ch3-box-zone) **Boxplot of blue tit nest depths for different woodland zones in Wytham Wood.**

```{r ch3-box-zone, fig.cap='(ref:ch3-box-zone)', fig.align='center', fig.dim=c(6, 4), message=FALSE, echo=TRUE, warning=FALSE}
cyan %>%
  ggplot(aes(y = depth, x = zone)) +  
  labs(y = "Depth",  
       x = "Zone") +  
  geom_boxplot(fill = "gray88") +  
  My_theme
```

Fig. \@ref(fig:ch3-box-zone) visualises the median and spread of the data, with the median represented as a thick horizontal line and the 25% and 75% quartiles (the inter quartile range or IQR) represented by the box. The black lines extending from the box represent the range of the data and the black dots are outliers. Outliers are arbitrarily identified as data points that are 3x lower or higher than the IQR. The boxplot shows that there are differences in the average nest depth among woodland zones. This finding suggests that there could be spatial differences in nest size that may be related to vegetation composition, or the blue tits that occupy different areas of Wytham Woods.

To identify outliers for continuous variables we use multi-panel dotplots. We first define a short _function_ for plotting a dotplot in our preferred layout:

```{r ch3-dot-function, echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
multi_dotplot <- function(filename, Xvar, Yvar){
  filename %>%  
    ggplot(aes(x = {{Xvar}})) +  
    geom_point(aes(y = {{Yvar}})) +  
    My_theme +  
    coord_flip()}
```

Then order the data in the sequence they appear in the dataframe `cyan`:

```{r ch3-order, message = FALSE, echo=TRUE, warning=FALSE}
cyan <- cyan %>%
  mutate(order = seq(1:nrow(cyan)))
```

And identify those continuous variables we wish to plot (`height`, `day`, `depth`):

```{r ch3-grid1, message = FALSE, echo=TRUE, warning=FALSE}
p1 <- multi_dotplot(cyan, order, height) + My_theme
p2 <- multi_dotplot(cyan, order, day)    + My_theme
p3 <- multi_dotplot(cyan, order, depth)  + My_theme
```

Using the `grid.arrange` command from the `gridExtra` package, we can arrange these plots in our preferred format:  

```{r ch3-dotplot1, fig.cap='(ref:ch3-dotplot1)', message = FALSE, echo=TRUE, warning=FALSE}
grid.arrange(p1, p2, p3, nrow = 1)
```

(ref:ch3-dotplot1) **Dotplots of the continuous variables height, day and depth. Data are arranged by the order they appear in the dataframe (bottom to top).**

In Fig. \@ref(fig:ch3-dotplot1) the dotplot for `day` shows no prominent outliers. However, for `height` there appears to be one nest box that is set unusually low and another unusually high. For `depth` there is one nest that is unusually deep.

Grubb’s test can be used to test whether the value that is farthest (above or below) the mean is an outlier. An outlier is identified from the difference between the outlier and the mean of all the values, divided by the standard deviation.

For nest depth we will test for a single outlier:

```{r ch3-grubb1, message = FALSE, echo=TRUE, warning=FALSE}
grubbs.test(cyan$depth, type = 10)
```

Grubb’s test shows that the single unusually high depth value (of 0.75) is indeed an outlier (the P-value is lower than the critical threshold of 0.05). However, Grubb’s test assumes these data are normally distributed – something we have yet to test.

For nest box height there appears to be an unusually high and low value. Consequently we modify the test to examine two outliers simultaneously by changing test ‘type’ to 11 (rather than 10 for a single outlier).

```{r ch3-grubb2, message = FALSE, echo=TRUE, warning=FALSE}
grubbs.test(cyan$height, type = 11)
```

The test indicates that the low (0.6 m) and high (3.5 m) nest boxes are both outliers. Even where outliers exist, before we consider dropping data from our analysis, we go on with our data exploration, but take note of the variables that have at least one outlier that might influence a subsequent analysis.

On the basis of Fig. \@ref(fig:ch3-dotplot1) we concluded that there were no outliers in the variable `day` based on our visual assessment. We can confirm that conclusion with a final Grubb’s test.

```{r ch3-grubb3, message = FALSE, echo=TRUE, warning=FALSE}
grubbs.test(cyan$day, type = 10)
```

The test indicates that the highest value (day 37) is not an outlier since the P-value exceeds 0.05. This means that our visual inspection of the data was accurate. We should not be overly reliant on tests, such as Grubb’s test, to make decisions about our data – visual inspection is often enough.

### Normality and homogeneity of response variable {#normality3}

An assumption of some statistical tests is that the response variable is normally distributed **at each covariate value**. The distribution of a continuous variable can be visualized by dividing the x-axis into “bins” and counting the number of observations in each bin as a frequency polygon using the `geom_freqpoly()` function from the `ggplot2` plotting package:

```{r ch3-freqpoly, fig.cap='(ref:ch3-freqpoly)', echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
cyan %>% ggplot(aes(depth)) +
  geom_freqpoly(bins = 7) +
  labs(x = "Nest depth", y = "Frequency") +
  My_theme
```

(ref:ch3-freqpoly) **Frequency polygon of nest depth for blue tits in Wytham Woods.**

The frequency polygon plot of the dependent variable (Fig. \@ref(fig:ch3-freqpoly)) shows a positive skew, which potentially indicates deviation from normality. However, this figure ignores the factors, such as nest height or zone, that may explain deviation from normality. Given that we already recognise that the distribution of nest depth may vary with woodland zone (Fig. \@ref(fig:ch3-box-zone)), it is not surprising that the data appear as they do. Outliers may also affect the distribution of the dependent variable. At this stage, then, we can proceed with the data exploration bearing in mind that the raw data values for the dependent variable are not entirely normally distributed.

It is possible to test for normality using the Shapiro-Wilk test. The null hypothesis for this test is that the distribution of the data follows a normal distribution. If the P-value is below 0.05 (P <0.05) the null hypothesis is rejected and the conclusion is that the data depart from normality.

```{r ch3-shapiro, message = FALSE, echo=FALSE, warning=FALSE}
shapiro.test(cyan$depth)
```

The test shows significant departure from normality (P <0.001).

_Homogeneity of variance_ is an even distribution of covariate values around the mean and is another important assumption of many statistical tests. Without homogeneity of variance estimated P-values are unreliable. There are several ways to measure homogeneity of variance.

To visualise the homogeneity of the response variable in relation to a categorical covariate a boxplot is illustrative. Fig. \@ref(fig:ch3-box-zone) showed variation in the spread of depth data among levels of the factor zone, possibly indicating a lack of homogeneity. A scatterplot is better to visualise homogeneity of variance in relation to a continuous covariate.

(ref:ch3-scatter2-cyan) **Scatterplot of `depth` and `height`. The mean for `depth` and `height` are added as horizontal and vertical dashed lines, respectively. The distribution of points in the four quadrants are similar, indicating homogeneity of the data.**

```{r ch3-scatter2-cyan, fig.cap='(ref:ch3-scatter2-cyan)', fig.align='center', fig.dim=c(6, 4), echo=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}

cyan %>% 
  ggplot(aes(x=height, y=depth)) +  
  geom_jitter(size=3, height = 0.05, width = 0.05, alpha = 0.5) +  
  geom_hline(yintercept=0.33, linetype="dashed") +  
  geom_vline(xintercept=2.19, linetype="dashed") +  
  labs(x = "Nest box height (m)",  
       y = "Nest depth") +  
  xlim(0,4) + ylim(0,0.8) +  
  My_theme
```

The scatterplot (Fig. \@ref(fig:ch3-scatter2-cyan)) shows a symmetrical cloud of points, indicating that the data probably do not deviate significantly from homogeneity. 

There are several tests of homogeneity of variance, should we need one, such as Bartlett's Test, the F-ratio test, and Levene's test. The first two of these tests assume normality of the data. If your data deviate from normality they should not be used. Levene's test does not assume normality. An alternative is the Brown & Forsythe test, which uses the median rather than mean in its estimation, and is robust to departures from normality. This test is based on Levene's test and can be obtained using the `levene.test()` function from the `lawstat` package:

```{r ch3-levene-cyan, message=FALSE, echo=TRUE, warning=FALSE}
leveneTest(depth ~ zone, cyan, center = median)
```

Which confirms the data do not deviate from homogeneity (P = 0.774).

### Balance of categorical variables {#balance3}  

Imbalance in data occurs when we have a categorical variable with markedly different numbers of observations of different levels. If a model contains one or more unbalanced variables, and particularly if variances among levels also differ, then fitted models have reduced power.

Imbalance can be identified using the table command from base R. We have two categorical variables of interest in the cyan dataframe.

```{r ch3-table-zone, message=FALSE, echo=TRUE, warning=FALSE}
table(cyan$zone)
```
Balance among woodland zones is poor. However, from Fig. \@ref(fig:ch3-box-zone) we have already seen that variances in nest depth do not vary greatly among zones. Consequently, this imbalance may not cause us serious problems.

The categorical variable `multi` indicates whether the female that built the nest bred more than once in that year (two levels; no or yes).

```{r ch3-table-multi, message=FALSE, echo=TRUE, warning=FALSE}
table(cyan$multi)
```

Balance between pairs that produced multiple clutches is also poor. A boxplot with illustrate differences in variance between levels.

(ref:ch3-box-multi) **Boxplot of nest depths for pairs that produced single or multiple broods.**

```{r ch3-box-multi, fig.cap='(ref:ch3-box-multi)', fig.align='center', fig.dim=c(6, 4), echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
cyan %>%  
  ggplot(aes(y=depth, x=multi)) +  
  labs(y="Depth",  
       x="Multi broods") +  
  geom_boxplot(fill="gray") +  
  My_theme
```

Variances in nest depth do not differ between pairs that produced single or multiple clutches (Fig. \@ref(fig:ch3-box-multi)). Consequently, the imbalance in sample sizes for these two groups is unlikely to cause problems.

### An excess of zeros in the response variable {#zeros3} 

Zeros should not be omitted from a dataset. However, an excess of zeros in the response variable, termed ‘zero inflation’, can cause problems with an analysis. Fortunately, there are a number of ways of dealing with zero inflation. The first step is to identify whether there is a potential problem. The percentage of zeros in the response variable can be estimated as:

```{r ch3-zeros, message=FALSE, echo=TRUE, warning=FALSE}
sum(cyan$depth == 0, na.rm = TRUE) * 100 / nrow(cyan)
```

There are no zeros in the response variable for this dataset. If there are zeros, how many would be too many? The question of how many zeros leads to zero inflation is often asked but cannot be answered without fitting a model and then running simulations from it to see how many zeros are predicted and then compared to the raw data.

### Multicollinearity among independent variables {#multico3} 

Along with normality of residuals and homogeneity of variance, an additional assumption of analyses that include several predictor variables is independence of the ‘independent’ variables. In ecological studies it is not unusual to collect a large number of variables that are often highly correlated. If independent variables in an analysis are correlated the variance associated with predictions will be affected.

Multicollinearity can be tested in several ways. We can obtain a comprehensive summary of the relationship between the model covariates using the `ggpairs` command from the `GGally` package.

First create an object vector comprising the variables of interest then plot:

(ref:ch3-pairs-cyan) **Pairplots of `year`, `height` and `day`. Upper right panels show pairwise Pearson correlations, with the number of stars proportional to the correlation coefficient (_r_).**

```{r ch3-pairs-cyan, fig.cap='(ref:ch3-pairs-cyan)', fig.align ='center', fig.dim = c(5,4), echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
cyan %>% 
    ggpairs(columns = c("year", "height", "day"))
```

The plot matrix (Fig. \@ref(fig:ch3-pairs-cyan)) shows `year` and `day` to be negatively associated. This is an interesting observation, since it implies that there has been a change in laying date with year, which may have ecological significance. We need to be aware of this negative correlation if we plan to use both these variables to model nest depth. 

### Relationships among response and independent variables {#relationships3}  

Visual inspection of the data using plots is a valuable step and will illustrate what relationships there are between variables in your dataframe. Do not be reluctant to spend time plotting and summarising your data before formally analysing them – this is time well spent and will help inform you about the peculiarities of your data and the appropriate approach to analyse them.

Below is R script to conduct a multi-panel scatterplot:

(ref:ch3-scatter-cyan) **Multipanel scatterplot of nest depth (`depth`) and nest box height (`height`) among woodland compartments (`zone`) with a line of best fit plotted to each.**

```{r ch3-scatter-cyan, fig.cap='(ref:ch3-scatter-cyan)', fig.align ='center', fig.dim = c(5,4), echo=TRUE, tidy=TRUE, message = FALSE, warning=FALSE, tidy.opts=list(width.cutoff=50)}
ggplot(cyan, aes(x = height, y = depth)) +  
  geom_point() +  
  geom_smooth(method = 'lm', se = FALSE) +  
  My_theme +  
  facet_wrap(~zone)
```

The plot of the data in Fig. \@ref(fig:ch3-scatter-cyan) does not suggest strongly non-linear patterns in the data. Fitted lines for the relationship between `height` and `depth` indicate that the nature of this relationship may be different for some woodland zones (e.g. ‘O’ and ‘CP’), suggesting that there may be interesting interactions present.

### Independence of the response variable {#independence3} 

A critical assumption of any data analysis is that each observation in a dataset is independent of all others. For some data this assumption is difficult to confirm but the risk of non-independence can be reduced by careful sampling. Strictly randomly collected samples will tend to be independent.

Additional information, such as spatial location or time of collection, can be included in a dataset. Spatial and temporal dependency in ecological and conservation data are common and require specific modelling approaches.

For the Wytham Woods blue tit data, there are fewer levels of nest box `id` than observations, which indicates there are multiple records (in different years) for different nests in the same nest box; i.e. some nests were built in the same nest boxes in different years. The repeated use of nest boxes in different years means that every row of data is not strictly independent. This situation is not fatal as long as we recognise that there is _dependency_ in the data. An option is to delete rows with duplicate records for the same nest box; though the problem then arises of which to remove. A second option is to accept a low level of dependency and report that fact in the results of a data analysis. A third (preferred) option is to include `id` as a _random_ term and fit a _mixed_ model; _mixed_ indicating the model contains a mixture of fixed and random terms.

## Results of the data exploration

The data exploration showed:

_1.	An outliers in the response variable `depth` and covariate `height`._  
_2.	A non-normally distributed but homogenous response variable._  
_3.	Good balance of categorical variable `zone`._  
_4.	No zeros in the response variable `depth`._  
_5.	Collinearity between the variables `day` and `year`._  
_6.	A potential interaction between `depth` and `zone`._  
_7.	Dependency in the data due to repeated sampling of the same nest boxes in different years._   

If we wish to go further with analysing these data we will need to address the problem of outliers. We will also need to consider non-normality and collinearity. The potential interaction we identified might inform our decisions about what model to fit. Finally, we need to be aware of the dependency in our data. 

## Conclusions

Data exploration is a crucial procedure that will save time by identifying potential problems in the data. It will help identify interesting patterns and will inform decisions on which analysis to use. 
<br>  
<br>  
**References**

O'Neill, L.G., Parker, T.H. & Griffith, S.C., 2018. Nest size is predicted by female identity and the local environment in the blue tit (_Cyanistes caeruleus_), but is not related to the nest size of the genetic or foster mother. _Royal Society Open Science_ 5, 172036.

Zuur, A.F., Ieno, E.N. and Elphick, C.S., 2010. A protocol for data exploration to avoid common statistical problems. _Methods in Ecology and Evolution_ 1, 3-14.  

